{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f90a1967-0666-42aa-8522-17691b1f6208",
   "metadata": {},
   "source": [
    "Name : Ishika Chittora\n",
    "Aim : Develop a model that can accurately recognize food items from images and estimate their calorie content, enabling users to track their dietary intake and make informed food choices n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d6ee9e2-75af-4566-a3f3-1191aec6f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.preprocessing import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "561c4b7a-dd26-4db7-9dc2-674cae450abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'C://Users//ISHIKA JAIN//Downloads//archive (1)//Indian Food Images//Indian Food Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f685b9-d2d1-445d-8ca5-57bb438563b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5df659a2-ac87-4515-b10d-bafa28f000a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image dimensions\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# Load the images and labels\n",
    "images = []\n",
    "labels = []\n",
    "for folder in os.listdir(dataset_path):\n",
    "    folder_path = os.path.join(dataset_path, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        label = folder\n",
    "        for file in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            if file.endswith('.jpg') or file.endswith('.png'):\n",
    "                img = Image.open(file_path)\n",
    "                img = img.resize((img_width, img_height))\n",
    "                images.append(np.array(img))\n",
    "                labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "529761b1-f98c-49b2-9ba3-863a340d2457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "n_samples = len(images)\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48a392ed-8106-43a1-8f00-9ef1e7152953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode = 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6be4ca88-c0eb-4e37-a58e-55629ae1bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54b95458-23de-4dbe-9402-2a493db5ba5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ISHIKA JAIN\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (32, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "C:\\Users\\ISHIKA JAIN\\anaconda3\\Lib\\site-packages\\keras\\src\\losses\\losses.py:27: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(32, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/100\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10:14\u001b[0m 43s/step - food_output_accuracy: 0.0000e+00 - loss: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ISHIKA JAIN\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:664: UserWarning: Gradients do not exist for variables ['kernel', 'bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2027s\u001b[0m 20s/step - food_output_accuracy: 0.0087 - loss: 0.0000e+00 - val_food_output_accuracy: 0.0188 - val_loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2385s\u001b[0m 24s/step - food_output_accuracy: 0.0087 - loss: 0.0000e+00 - val_food_output_accuracy: 0.0188 - val_loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1820s\u001b[0m 18s/step - food_output_accuracy: 0.0087 - loss: 0.0000e+00 - val_food_output_accuracy: 0.0188 - val_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1756s\u001b[0m 18s/step - food_output_accuracy: 0.0087 - loss: 0.0000e+00 - val_food_output_accuracy: 0.0188 - val_loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1926s\u001b[0m 19s/step - food_output_accuracy: 0.0087 - loss: 0.0000e+00 - val_food_output_accuracy: 0.0188 - val_loss: 0.0000e+00\n",
      "Epoch 6/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1562s\u001b[0m 16s/step - food_output_accuracy: 0.0087 - loss: 0.0000e+00 - val_food_output_accuracy: 0.0188 - val_loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2001s\u001b[0m 20s/step - food_output_accuracy: 0.0087 - loss: 0.0000e+00 - val_food_output_accuracy: 0.0188 - val_loss: 0.0000e+00\n",
      "Epoch 8/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1507s\u001b[0m 15s/step - food_output_accuracy: 0.0087 - loss: 0.0000e+00 - val_food_output_accuracy: 0.0188 - val_loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1550s\u001b[0m 16s/step - food_output_accuracy: 0.0087 - loss: 0.0000e+00 - val_food_output_accuracy: 0.0188 - val_loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1743s\u001b[0m 17s/step - food_output_accuracy: 0.0087 - loss: 0.0000e+00 - val_food_output_accuracy: 0.0188 - val_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "food_output = Dense(1, activation='softmax', name='food_output')(x)\n",
    "calorie_output = Dense(1, activation='linear', name='calorie_output')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=[food_output, calorie_output])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss={'food_output': 'categorical_crossentropy', 'calorie_output': 'mean_squared_error'},\n",
    "              metrics={'food_output': 'accuracy', 'calorie_output': 'mean_absolute_error'})\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a LabelEncoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit the LabelEncoder to your labels and transform them to numerical labels\n",
    "train_labels_encoded = le.fit_transform(train_labels)\n",
    "test_labels_encoded = le.transform(test_labels)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels_encoded))\n",
    "train_dataset = train_dataset.batch(32)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels_encoded))\n",
    "test_dataset = test_dataset.batch(32)\n",
    "\n",
    "history = model.fit(train_dataset, epochs=10, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aa5e7bab-e595-4b9b-bf31-a7d9b2d837ad",
   "metadata": {},
   "source": [
    "# Define the model\n",
    "model = Model(inputs=inputs, outputs=[food_output, calorie_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss={'food_output': 'categorical_crossentropy', 'calorie_output': 'mean_squared_error'},\n",
    "              metrics={'food_output': 'accuracy', 'calorie_output': 'mae'})\n",
    "\n",
    "# Evaluate the model\n",
    "loss, food_accuracy, calorie_mae = model.evaluate(test_dataset)\n",
    "\n",
    "# Print the results\n",
    "print(f'Test loss: {loss:.3f}')\n",
    "print(f'Test food accuracy: {food_accuracy:.3f}')\n",
    "print(f'Test calorie MAE: {calorie_mae:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "096ae589-881e-43a4-8e70-2ef60ca5f4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 5s/step - food_output_accuracy: 0.0163 - loss: 0.0000e+00\n",
      "Test food accuracy: 0.000\n",
      "Test calorie MAE: 0.019\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 5s/step\n",
      "Food prediction: ['adhirasam']\n",
      "Calorie prediction: 55004.27\n",
      "---\n",
      "Food prediction: ['adhirasam']\n",
      "Calorie prediction: 52830.86\n",
      "---\n",
      "Food prediction: ['adhirasam']\n",
      "Calorie prediction: 43506.91\n",
      "---\n",
      "Food prediction: ['adhirasam']\n",
      "Calorie prediction: 32937.86\n",
      "---\n",
      "Food prediction: ['adhirasam']\n",
      "Calorie prediction: 28855.29\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model , \n",
    "food_accuracy, calorie_mae = model.evaluate(test_dataset)\n",
    "#print(f'Test loss: {loss:.3f}')\n",
    "print(f'Test food accuracy: {food_accuracy:.3f}')\n",
    "print(f'Test calorie MAE: {calorie_mae:.3f}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_dataset)\n",
    "\n",
    "# Unpack the predictions into food and calorie predictions\n",
    "food_predictions, calorie_predictions = predictions\n",
    "\n",
    "# Print some predictions\n",
    "# Iterate over the predictions and print them\n",
    "for i in range(5):\n",
    "    # Get the predicted food class\n",
    "    predicted_food_class = np.argmax(food_predictions[i])\n",
    "    \n",
    "    # Get the predicted calorie value\n",
    "    predicted_calorie_value = calorie_predictions[i][0]\n",
    "    \n",
    "    # Print the predictions\n",
    "    print(f'Food prediction: {le.inverse_transform([predicted_food_class])}')\n",
    "    print(f'Calorie prediction: {predicted_calorie_value:.2f}')\n",
    "    print('---')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
